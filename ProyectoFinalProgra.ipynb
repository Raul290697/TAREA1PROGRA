{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+iQtFtXcTfQvrH0vKMbez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raul290697/TAREA1PROGRA/blob/main/ProyectoFinalProgra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tJIv0YZSR6U",
        "outputId": "faaf9546-9e94-4b80-f139-571cdc620469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTADOS DE LA EVALUACIÓN DE MODELOS:\n",
            "\n",
            "Modelo: Logistic Regression\n",
            "Accuracy Entrenamiento: 0.9914\n",
            "Accuracy Validación: 0.9733\n",
            "F1-score Validación: 0.9655\n",
            "Matriz de Confusión:\n",
            "[[90  2]\n",
            " [ 2 56]]\n",
            "Validación Cruzada (mean ± std): 0.9800 ± 0.0126\n",
            "\n",
            "Modelo: KNN\n",
            "Accuracy Entrenamiento: 0.9771\n",
            "Accuracy Validación: 0.9733\n",
            "F1-score Validación: 0.9649\n",
            "Matriz de Confusión:\n",
            "[[91  1]\n",
            " [ 3 55]]\n",
            "Validación Cruzada (mean ± std): 0.9720 ± 0.0039\n",
            "\n",
            "Modelo: SVM\n",
            "Accuracy Entrenamiento: 0.9885\n",
            "Accuracy Validación: 0.9800\n",
            "F1-score Validación: 0.9739\n",
            "Matriz de Confusión:\n",
            "[[91  1]\n",
            " [ 2 56]]\n",
            "Validación Cruzada (mean ± std): 0.9740 ± 0.0185\n",
            "\n",
            "Modelo: Decision Tree\n",
            "Accuracy Entrenamiento: 1.0000\n",
            "Accuracy Validación: 0.9267\n",
            "F1-score Validación: 0.9060\n",
            "Matriz de Confusión:\n",
            "[[86  6]\n",
            " [ 5 53]]\n",
            "Validación Cruzada (mean ± std): 0.9118 ± 0.0162\n",
            "\n",
            "Modelo: Random Forest\n",
            "Accuracy Entrenamiento: 1.0000\n",
            "Accuracy Validación: 0.9533\n",
            "F1-score Validación: 0.9381\n",
            "Matriz de Confusión:\n",
            "[[90  2]\n",
            " [ 5 53]]\n",
            "Validación Cruzada (mean ± std): 0.9519 ± 0.0075\n",
            "\n",
            "COMPARACIÓN FINAL:\n",
            "El Árbol de Decisión NO es el mejor modelo.\n",
            "Otros modelos con mayor exactitud de validación: ['Logistic Regression', 'KNN', 'SVM', 'Random Forest']\n",
            "Aunque el árbol de decisión tiene ventajas interpretables (facilidad de interpretación,\n",
            "reducción del espacio de hipótesis), en este caso su desempeño de exactitud no superó\n",
            "a otros clasificadores. Si quisiéramos el mejor árbol, podríamos ajustar hiperparámetros,\n",
            "como la profundidad máxima, criterios de división, etc., para mejorar su rendimiento.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Este módulo entrena y compara diferentes clasificadores (Regresión Logística, KNN, SVM, Árbol de Decisión, Random Forest)\n",
        "usando el conjunto de datos de cancer (cancer.xlsx).\n",
        "El análisis consiste en:\n",
        "- Lectura de datos\n",
        "- Limpieza y separación de características y etiqueta\n",
        "- División entre entrenamiento y validación\n",
        "- Entrenamiento de múltiples clasificadores en una clase Clasificadores\n",
        "- Evaluación con diferentes métricas y validación cruzada\n",
        "- Comparación entre métodos y selección del mejor árbol de decisión\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import traceback\n",
        "import logging\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configura el sistema para mostrar mensajes de error en la terminal\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "\n",
        "\n",
        "class Clasificadores:\n",
        "    \"\"\"\n",
        "    Clase que encapsula diversos clasificadores solicitados.\n",
        "    Se almacenan como atributos:\n",
        "    - Regresión Logística\n",
        "    - KNN\n",
        "    - SVM\n",
        "    - Árbol de Decisión\n",
        "    - Random Forest\n",
        "    \"\"\"\n",
        "    def __init__(self, random_state=42):\n",
        "        \"\"\"\n",
        "        Inicializa los clasificadores con algunos hiperparámetros por defecto.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        random_state : int\n",
        "            Semilla para la reproducibilidad.\n",
        "        \"\"\"\n",
        "        self.log_reg = LogisticRegression(random_state=random_state, max_iter=1000)\n",
        "        self.knn = KNeighborsClassifier(n_neighbors=5)\n",
        "        self.svm = SVC(random_state=random_state, probability=True)\n",
        "        self.decision_tree = DecisionTreeClassifier(random_state=random_state)\n",
        "        self.random_forest = RandomForestClassifier(random_state=random_state)\n",
        "\n",
        "    def entrenar_todos(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Entrena todos los clasificadores con los datos de entrenamiento.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X_train : np.ndarray\n",
        "            Características de entrenamiento\n",
        "        y_train : np.ndarray\n",
        "            Etiquetas de entrenamiento\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.log_reg.fit(X_train, y_train)\n",
        "            self.knn.fit(X_train, y_train)\n",
        "            self.svm.fit(X_train, y_train)\n",
        "            self.decision_tree.fit(X_train, y_train)\n",
        "            self.random_forest.fit(X_train, y_train)\n",
        "        except Exception as e:\n",
        "            logging.error(\"Error al entrenar los clasificadores: %s\", e)\n",
        "            traceback.print_exc(file=sys.stdout)\n",
        "\n",
        "\n",
        "def cargar_datos(ruta_archivo):\n",
        "    \"\"\"\n",
        "    Carga el archivo xlsx con los datos de cáncer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ruta_archivo : str\n",
        "        Ruta al archivo .xlsx\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame con los datos cargados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(ruta_archivo)\n",
        "        return df\n",
        "    except FileNotFoundError as fnf_error:\n",
        "        logging.error(\"Archivo no encontrado: %s\", fnf_error)\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        logging.error(\"Error al leer el archivo: %s\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "def preparar_datos(df):\n",
        "    \"\"\"\n",
        "    Prepara el conjunto de datos:\n",
        "    - Elimina columna 'id'\n",
        "    - Separa en X (características) e y (etiqueta)\n",
        "    - Estandariza X\n",
        "    - Convierte la columna diagnosis a valores binarios (ej. M=1, B=0)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame con todas las columnas.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.ndarray\n",
        "        Características escaladas.\n",
        "    y : np.ndarray\n",
        "        Etiquetas binarias.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Verificar si existe la columna 'id' y eliminarla\n",
        "        if 'id' in df.columns:\n",
        "            df = df.drop(columns=['id'])\n",
        "\n",
        "        # Suponemos que la columna 'diagnosis' es la etiqueta\n",
        "        if 'diagnosis' not in df.columns:\n",
        "            raise ValueError(\"La columna 'diagnosis' no está presente en el DataFrame.\")\n",
        "\n",
        "        # Codificar diagnosis: M=1, B=0\n",
        "        df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "        if df['diagnosis'].isnull().any():\n",
        "            raise ValueError(\"La columna 'diagnosis' contiene valores no esperados.\")\n",
        "\n",
        "        y = df['diagnosis'].values\n",
        "        X = df.drop(columns=['diagnosis']).values\n",
        "\n",
        "        # Estandarización de X\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        return X_scaled, y\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(\"Error en la preparación de datos: %s\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "def evaluar_modelo(modelo, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Evalúa un modelo dado sobre conjuntos de entrenamiento y prueba,\n",
        "    mostrando métricas como exactitud, matriz de confusión y F1-score.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    modelo : objeto clasificador entrenado\n",
        "    X_train : np.ndarray\n",
        "        Datos de entrenamiento\n",
        "    X_test : np.ndarray\n",
        "        Datos de prueba\n",
        "    y_train : np.ndarray\n",
        "        Etiquetas de entrenamiento\n",
        "    y_test : np.ndarray\n",
        "        Etiquetas de prueba\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    resultados : dict\n",
        "        Diccionario con métricas calculadas.\n",
        "    \"\"\"\n",
        "    y_pred_train = modelo.predict(X_train)\n",
        "    y_pred_test = modelo.predict(X_test)\n",
        "\n",
        "    acc_train = accuracy_score(y_train, y_pred_train)\n",
        "    acc_test = accuracy_score(y_test, y_pred_test)\n",
        "    f1 = f1_score(y_test, y_pred_test)\n",
        "    cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    resultados = {\n",
        "        'accuracy_train': acc_train,\n",
        "        'accuracy_test': acc_test,\n",
        "        'f1_test': f1,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "    return resultados\n",
        "\n",
        "\n",
        "def validacion_cruzada(modelo, X, y, cv=5):\n",
        "    \"\"\"\n",
        "    Realiza validación cruzada con el modelo especificado.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    modelo : objeto clasificador\n",
        "        Modelo a validar.\n",
        "    X : np.ndarray\n",
        "        Datos de características.\n",
        "    y : np.ndarray\n",
        "        Etiquetas.\n",
        "    cv : int\n",
        "        Número de particiones para la validación cruzada.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mean_score : float\n",
        "        Promedio de exactitud en la validación cruzada.\n",
        "    std_score : float\n",
        "        Desviación estándar de las puntuaciones.\n",
        "    \"\"\"\n",
        "    scores = cross_val_score(modelo, X, y, cv=cv, scoring='accuracy')\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ruta del archivo (aquí puse el archivo en la misma carpeta)\n",
        "    ruta = \"/content/cancer.xlsx\"\n",
        "\n",
        "    # Cargar datos\n",
        "    df = cargar_datos(ruta)\n",
        "\n",
        "    # Preparar datos\n",
        "    X, y = preparar_datos(df)\n",
        "\n",
        "    # Dividir en entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Crear instancia de la clase clasificadores\n",
        "    clasificadores = Clasificadores(random_state=42)\n",
        "\n",
        "    # Entrenar todos los clasificadores\n",
        "    clasificadores.entrenar_todos(X_train, y_train)\n",
        "\n",
        "    # Evaluar todos los clasificadores\n",
        "    modelos = {\n",
        "        'Logistic Regression': clasificadores.log_reg,\n",
        "        'KNN': clasificadores.knn,\n",
        "        'SVM': clasificadores.svm,\n",
        "        'Decision Tree': clasificadores.decision_tree,\n",
        "        'Random Forest': clasificadores.random_forest\n",
        "    }\n",
        "\n",
        "    # Se guardarán resultados para comparar\n",
        "    resultados_globales = {}\n",
        "\n",
        "    for nombre, modelo in modelos.items():\n",
        "        res = evaluar_modelo(modelo, X_train, X_test, y_train, y_test)\n",
        "        cv_mean, cv_std = validacion_cruzada(modelo, X, y, cv=5)\n",
        "        res['cv_mean_acc'] = cv_mean\n",
        "        res['cv_std_acc'] = cv_std\n",
        "        resultados_globales[nombre] = res\n",
        "\n",
        "    # resultados\n",
        "    print(\"RESULTADOS DE LA EVALUACIÓN DE MODELOS:\")\n",
        "    for nombre, metrica in resultados_globales.items():\n",
        "        print(f\"\\nModelo: {nombre}\")\n",
        "        print(f\"Accuracy Entrenamiento: {metrica['accuracy_train']:.4f}\")\n",
        "        print(f\"Accuracy Validación: {metrica['accuracy_test']:.4f}\")\n",
        "        print(f\"F1-score Validación: {metrica['f1_test']:.4f}\")\n",
        "        print(\"Matriz de Confusión:\")\n",
        "        print(metrica['confusion_matrix'])\n",
        "        print(f\"Validación Cruzada (mean ± std): {metrica['cv_mean_acc']:.4f} ± {metrica['cv_std_acc']:.4f}\")\n",
        "\n",
        "    # Identificar cuál árbol de decisión fue el mejor:\n",
        "    # En este caso, sólo entrenamos un árbol de decisión simple, así que la comparación\n",
        "    # se haría entre el árbol de decisión y los demás clasificadores.\n",
        "\n",
        "\n",
        "    # Supongamos que el árbol de decisión es el \"mejor\" si obtiene la mayor exactitud de validación.\n",
        "    decision_tree_acc = resultados_globales['Decision Tree']['accuracy_test']\n",
        "    # Comparar con los otros\n",
        "    mejores_que_arbol = [m for m, r in resultados_globales.items() if r['accuracy_test'] > decision_tree_acc]\n",
        "\n",
        "    print(\"\\nCOMPARACIÓN FINAL:\")\n",
        "    if len(mejores_que_arbol) == 0:\n",
        "        print(\"El Árbol de Decisión es el mejor modelo en términos de exactitud de validación.\")\n",
        "        print(\"Razón: Obtuvo la mayor exactitud en el conjunto de validación en comparación con otros métodos.\")\n",
        "    else:\n",
        "        print(\"El Árbol de Decisión NO es el mejor modelo.\")\n",
        "        print(\"Otros modelos con mayor exactitud de validación:\", mejores_que_arbol)\n",
        "        print(\"Aunque el árbol de decisión tiene ventajas interpretables (facilidad de interpretación,\")\n",
        "        print(\"reducción del espacio de hipótesis), en este caso su desempeño de exactitud no superó\")\n",
        "        print(\"a otros clasificadores. Si quisiéramos el mejor árbol, podríamos ajustar hiperparámetros,\")\n",
        "        print(\"como la profundidad máxima, criterios de división, etc., para mejorar su rendimiento.\")\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(model, X_test, y_test, model_name, save_path='images/'):\n",
        "    \"\"\"\n",
        "    Genera y guarda una matriz de confusión para un modelo específico.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Modelo entrenado.\n",
        "    - X_test: Conjunto de características de prueba.\n",
        "    - y_test: Etiquetas de prueba.\n",
        "    - model_name: Nombre del modelo (para el título y el nombre del archivo).\n",
        "    - save_path: Carpeta donde se guardará la imagen.\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Matriz de Confusión - {model_name}')\n",
        "    plt.xlabel('Predicción')\n",
        "    plt.ylabel('Realidad')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_path}confusion_{model_name.replace(' ', '_').lower()}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Generar matrices de confusión para cada modelo\n",
        "modelos = {\n",
        "    'Logistic Regression': clasificadores.log_reg,\n",
        "    'KNN': clasificadores.knn,\n",
        "    'SVM': clasificadores.svm,\n",
        "    'Decision Tree': clasificadores.decision_tree,\n",
        "    'Random Forest': clasificadores.random_forest,\n",
        "}\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    plot_confusion_matrix(modelo, X_test, y_test, nombre)\n",
        "\n",
        "\n",
        "def plot_roc_curves(modelos, X_test, y_test, save_path='images/'):\n",
        "    \"\"\"\n",
        "    Genera y guarda las curvas ROC para múltiples modelos.\n",
        "\n",
        "    Parameters:\n",
        "    - modelos: Diccionario con nombres y modelos entrenados.\n",
        "    - X_test: Conjunto de características de prueba.\n",
        "    - y_test: Etiquetas de prueba.\n",
        "    - save_path: Carpeta donde se guardará la imagen.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for nombre, modelo in modelos.items():\n",
        "        if hasattr(modelo, \"predict_proba\"):\n",
        "            y_prob = modelo.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_prob = modelo.decision_function(X_test)\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{nombre} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Línea Base (AUC = 0.50)')\n",
        "    plt.xlabel('Tasa de Falsos Positivos')\n",
        "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "    plt.title('Curvas ROC de los Modelos')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_path}roc_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Generar curva ROC\n",
        "plot_roc_curves(modelos, X_test, y_test)"
      ]
    }
  ]
}